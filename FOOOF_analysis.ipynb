{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from scipy import signal as sg\n",
    "from fooof import FOOOF\n",
    "import os\n",
    "import json\n",
    "from fooof.sim.gen import gen_aperiodic\n",
    "import pyreadstat\n",
    "import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNT import path\n",
    "import_cnt = '[INSERT PATH TO CNT FILES]'\n",
    "\n",
    "#Project name string\n",
    "project_name = '[INSERT PROJECT NAME]'\n",
    "\n",
    "# home directory: where this script is located\n",
    "home_dir = os.getcwd()\n",
    "\n",
    "# Make a directory called psd_{project_name} if it doesnt exist\n",
    "if not os.path.exists(f'{home_dir}/psd_{project_name}'):\n",
    "    os.makedirs(f'{home_dir}/psd_{project_name}')\n",
    "psd_path = f'{home_dir}/psd_{project_name}'\n",
    "\n",
    "#Make a direct called fooof_{project_name} if it doesnt exist\n",
    "if not os.path.exists(f'{home_dir}/fooof_{project_name}'):\n",
    "    os.makedirs(f'{home_dir}/fooof_{project_name}')\n",
    "fooof_path = f'{home_dir}/fooof_{project_name}'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of fft points\n",
    "var_n_fft = 1024\n",
    "\n",
    "# fooof fit frequency range\n",
    "freq_range = [1, 55]\n",
    "\n",
    "# fooof fit mode\n",
    "mode = 'knee'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Get list of all files in directory\n",
    "file_list = os.listdir(import_cnt)\n",
    "print(file_list)\n",
    "#Get list of all files that end with .cnt\n",
    "subject_list = [i.split('_')[0] for i in file_list if i.endswith('.cnt')]\n",
    "cnt_list = [i for i in file_list if i.endswith('.cnt')]\n",
    "#Sort list of cnt files\n",
    "cnt_list.sort()\n",
    "subject_list = list(set(subject_list.copy()))\n",
    "subject_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_path = import_cnt\n",
    "export_path = psd_path\n",
    "\n",
    "fooof_dict = {}\n",
    "spec_dict = {}\n",
    "freq_dict = {}\n",
    "\n",
    "spec_list = []\n",
    "epoch_num_list = []\n",
    "for i in subject_list:\n",
    "    if (f'{i}_{project_name}_psd.json') in os.listdir(export_path):\n",
    "        print('file already exists')\n",
    "        continue\n",
    "\n",
    "    #Get items in cnt_list that are in subject_list\n",
    "    one_two_epoch_list = []\n",
    "    for j in cnt_list:\n",
    "        if i in j:\n",
    "            file_path = os.path.join(import_path, j)\n",
    "            print(file_path)\n",
    "            raw_cnt  = mne.io.read_raw_cnt(file_path, data_format = 'int32', preload=True)\n",
    "            onsets = raw_cnt.annotations.onset\n",
    "            durations = raw_cnt.annotations.duration\n",
    "            last_annotation = onsets[-1] + durations[-1]\n",
    "            raw_cnt.annotations.append(onset = last_annotation, duration = 100000, description = 'BAD_1')\n",
    "            epoch_rest = mne.make_fixed_length_epochs(raw_cnt, 2.048, preload=True)\n",
    "            epoch_rest.apply_baseline(baseline=(None, None))\n",
    "            one_two_epoch_list.append(epoch_rest)\n",
    "    epochs = mne.concatenate_epochs(one_two_epoch_list)\n",
    "    # if len(epochs) < 29:\n",
    "    #     print('too few epochs')\n",
    "    #     with open('/home/woess/mnt/d/ADOLREST12/log_EC.txt', 'a') as f:\n",
    "    #         f.write(f'{i} too few epochs')\n",
    "    #     continue\n",
    "\n",
    "    psd = epochs.compute_psd(method='welch', n_fft =var_n_fft).average()\n",
    "    #Create json object to store psd data\n",
    "    psd_dict = {}\n",
    "    psd_dict['spec'] = psd.get_data().tolist()\n",
    "    psd_dict['freq'] = psd.freqs.tolist()\n",
    "    psd_dict['epoch_num'] = len(epochs)\n",
    "    psd_dict['subject'] = i\n",
    "    psd_dict['ch_names'] = psd.ch_names\n",
    "    #Export psd data as json\n",
    "    with open(os.path.join(psd_path, f'{i}_{project_name}_psd.json'), 'w') as f:\n",
    "        json.dump(psd_dict, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Get list of all files in directory\n",
    "file_list = os.listdir(psd_path)\n",
    "print(file_list)\n",
    "#Get list of all files that end with .cnt\n",
    "file_list.sort()\n",
    "\n",
    "df_fooof_list = []\n",
    "df_fooof_func_list = []\n",
    "spec_list = []\n",
    "bands = {'delta': [1, 4],\n",
    "        'theta': [4, 8],\n",
    "        'alpha': [8, 13],\n",
    "        'beta': [13, 30],\n",
    "        'gamma': [30, 50]}\n",
    "\n",
    "loop = 0\n",
    "for i in file_list:\n",
    "    os.chdir(import_path)\n",
    "    if i.endswith('.json'):\n",
    "        with open(os.path.join(psd_path, i)) as f:\n",
    "            loop += 1\n",
    "        \n",
    "            data = json.load(f)\n",
    "            freqs = np.array(data['freq'])\n",
    "            print(i)\n",
    "            file = i\n",
    "        for index, spectrum in enumerate(data['spec']):\n",
    "    \n",
    "            spectrum = np.array(spectrum)\n",
    "            # Create FOOOF object\n",
    "            fm = FOOOF(verbose=False, aperiodic_mode=mode)\n",
    "            print(data['ch_names'][index])\n",
    "            # If there is a Dataerror, skip the channel\n",
    "            try:\n",
    "                fm.fit(freqs, spectrum, freq_range=freq_range)\n",
    "            except:\n",
    "                #write to log file\n",
    "                with open(f'{home_dir}/log_{project_name}.txt', 'a') as f:\n",
    "                    f.write(f'Error in {file} at channel {data[\"ch_names\"][index]} \\n')\n",
    "                continue\n",
    "\n",
    "            #Remove first frequency point at 0 Hz\n",
    "            spectrum = spectrum[1:]\n",
    "            freqs = freqs[1:]\n",
    "            \n",
    "            ap_spec = 10**gen_aperiodic(freqs, fm.aperiodic_params_) \n",
    "            p_spec = spectrum - ap_spec\n",
    "            \n",
    "            # Create empty dataframe\n",
    "            df_fooof = pd.DataFrame()\n",
    "            df_fooof_func = pd.DataFrame()\n",
    "            # Add aperiodic series\n",
    "            df_fooof_func['pc'] = p_spec\n",
    "            df_fooof_func['apc'] = ap_spec\n",
    "            df_fooof_func['psd'] = spectrum\n",
    "            df_fooof_func['freqs'] = freqs\n",
    "            df_fooof_func['subject'] = data['subject']\n",
    "            df_fooof_func['channel'] = data['ch_names'][index]\n",
    "            df_fooof_func['epoch_num'] = data['epoch_num']\n",
    "            #Generate series 0-len(freqs) for plotting\n",
    "            df_fooof_func['num'] = np.arange(0, len(freqs))\n",
    "\n",
    "            offset =  fm.aperiodic_params_[0]\n",
    "            if mode == 'knee':\n",
    "                knee = fm.aperiodic_params_[1]\n",
    "                exponent = fm.aperiodic_params_[2]\n",
    "            else:\n",
    "                exponent = fm.aperiodic_params_[1]\n",
    "            df_fooof['ap_offset'] = [offset]\n",
    "            if (mode == 'knee'):\n",
    "                df_fooof['ap_knee'] = [knee]\n",
    "            df_fooof['ap_exponent'] = [exponent]\n",
    "            df_fooof['r_squared'] = [fm.r_squared_]\n",
    "            df_fooof['error'] = [fm.error_]\n",
    "            df_fooof['subject'] = data['subject']\n",
    "            df_fooof['channel'] = data['ch_names'][index]\n",
    "\n",
    "            #Add peak parameters in band\n",
    "            # Convert the peak_params_ to a dataframe\n",
    "            params_df = pd.DataFrame(fm.peak_params_, columns=['CF', 'PW', 'BW'])\n",
    "\n",
    "            # Create a function to get the peak_nums\n",
    "            def get_peak_nums(df, bands):\n",
    "                peak_nums = {}\n",
    "                for band in bands:\n",
    "                    peak_nums[band] = len(df[df['CF'].between(bands[band][0], bands[band][1], inclusive='left')])\n",
    "                return peak_nums\n",
    "\n",
    "            # Call the function to get the peak_nums dictionary\n",
    "            peak_nums = get_peak_nums(params_df, bands)\n",
    "\n",
    "            # Iterate over the bands and create the columns in df_fooof\n",
    "            for band, band_limits in bands.items():\n",
    "                band_df = params_df[params_df['CF'].between(bands[band][0], bands[band][1], inclusive='left')].reset_index(drop=True)\n",
    "                for i in range(peak_nums[band]):\n",
    "                    df_fooof[f'{band}_CF_{i}'] = [band_df.loc[i, 'CF']]\n",
    "                    df_fooof[f'{band}_PW_{i}'] = [band_df.loc[i, 'PW']]\n",
    "                    df_fooof[f'{band}_BW_{i}'] = [band_df.loc[i, 'BW']]\n",
    "            \n",
    "            df_fooof_list.append(df_fooof)\n",
    "            df_fooof_func_list.append(df_fooof_func)\n",
    "            # #Export to csv\n",
    "            # df_fooof.to_csv(f\"fooof_{sub_chan['subject'].iloc[0]}_{sub_chan['channel'].iloc[0]}.csv\")\n",
    "            # df_fooof_func.to_csv(f\"fooof_func_{sub_chan['subject'].iloc[0]}_{sub_chan['channel'].iloc[0]}.csv\")\n",
    "            with open(os.path.join(fooof_path, f\"{file[:-5]}_{df_fooof_func['channel'].to_list()[0]}_{project_name}_func.json\"), 'w') as f:\n",
    "                json.dump(df_fooof_func.to_json(), f)\n",
    "            with open(os.path.join(fooof_path, f\"{file[:-5]}_{df_fooof['channel'].to_list()[0]}_{project_name}.json\"), 'w') as f:\n",
    "                json.dump(df_fooof.to_json(), f)\n",
    "\n",
    "#Concatenate all dataframes\n",
    "df_fooof = pd.concat(df_fooof_list)\n",
    "df_fooof_func = pd.concat(df_fooof_func_list)\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "now = now.strftime(\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "# Export to csv\n",
    "if f\"fooof_comb_{project_name}_{now}.csv\" not in os.listdir(home_dir):\n",
    "    df_fooof.to_csv(f\"fooof_comb_{project_name}_{now}.csv\")\n",
    "if f\"fooof_func_comb_{project_name}_{now}.csv\" not in os.listdir(home_dir):\n",
    "    df_fooof_func.to_csv(f\"fooof_func_comb_{project_name}_{now}.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_path = home_dir\n",
    "os.chdir(import_path)\n",
    "#Get list of all files in directory\n",
    "file_list = os.listdir()\n",
    "print(file_list)\n",
    "#Get list of all files that end with .cnt\n",
    "file_list.sort()\n",
    "print(file_list)\n",
    "\n",
    "#Get all files that contain string 'fooof_'\n",
    "fooof_file_list = [i for i in file_list if 'fooof_' in i]\n",
    "fooof_func_list = [i for i in file_list if 'fooof_func' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(import_path)\n",
    "#Import df_fooof and df_fooof_func\n",
    "df_fooof = pd.read_csv(fooof_file_list[-1])\n",
    "df_fooof_func = pd.read_csv(fooof_func_list[-1])\n",
    "#Drop unnamed column\n",
    "df_fooof = df_fooof.drop(columns=['Unnamed: 0'])\n",
    "df_fooof_func = df_fooof_func.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df_fooof = df_fooof[~df_fooof['channel'].isin(['M2', 'EKG', 'HEOG', 'VEOG'])]\n",
    "df_fooof_func = df_fooof_func[~df_fooof_func['channel'].isin(['M2', 'EKG', 'HEOG', 'VEOG'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fooof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fooof_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Round frequencies to 2 decimals\n",
    "df_fooof_func['freq'] = df_fooof_func['freqs'].round(2) \n",
    "df_fooof_func['freq'] = df_fooof_func['freq'].astype(str) + 'H'\n",
    "df_fooof_func\n",
    "df_select = df_fooof_func[df_fooof_func['num'] <120]\n",
    "\n",
    "# Convert offset to microvolts\n",
    "df_fooof_microvolts = df_fooof.apply(lambda x: np.log10(10**x*10**12) if 'offset' in x.name else x, axis=0)\n",
    "\n",
    "#Get column names in df_fooof\n",
    "fooof_cols = df_fooof.columns.to_list()\n",
    "#Remove subject and channel\n",
    "fooof_cols.remove('subject')\n",
    "fooof_cols.remove('channel')\n",
    "fooof_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wide_df_fooof_microvolts = df_fooof_microvolts.pivot(\n",
    "                    index=['subject'], \n",
    "                    columns=['channel'], \n",
    "                    values=fooof_cols\n",
    "                    )\n",
    "\n",
    "\n",
    "value = wide_df_fooof_microvolts.columns.get_level_values(0)\n",
    "channel = wide_df_fooof_microvolts.columns.get_level_values(1)\n",
    "\n",
    "# #Set the index to source_fileS\n",
    "# wide_df_fcz = wide_df_fcz.set_index(('lab_num'))\n",
    "\n",
    "#Rename the columns\n",
    "wide_df_fooof_microvolts.columns = project_name + '_' + value + '_' + channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wide_df_fooof_func = df_select.pivot(\n",
    "                    index=['subject'], \n",
    "                    columns=['channel', 'freq'], \n",
    "                    values=['psd', 'apc', 'pc', 'epoch_num']\n",
    "                    )\n",
    "\n",
    "\n",
    "value = wide_df_fooof_func.columns.get_level_values(0)\n",
    "channel = wide_df_fooof_func.columns.get_level_values(1)\n",
    "num = wide_df_fooof_func.columns.get_level_values(2)\n",
    "\n",
    "# #Set the index to source_fileS\n",
    "# wide_df_fcz = wide_df_fcz.set_index(('lab_num'))\n",
    "\n",
    "#Rename the columns\n",
    "wide_df_fooof_func.columns = project_name + '_' + value + '_' + channel + '_' + num "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiply every column but the last one by 10^12\n",
    "wide_fooof_func_microvolts = pd.concat([wide_df_fooof_func.filter(regex='(psd)|(apc)|(pc)') * 1e12, wide_df_fooof_func.filter(regex='(epoch_num)')], axis=1)\n",
    "\n",
    "#Reset index\n",
    "wide_fooof_func_microvolts.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_cols = [col for col in wide_fooof_func_microvolts.columns if 'epoch_num' in col]\n",
    "wide_fooof_func_microvolts = wide_fooof_func_microvolts.drop(epoch_cols[1:], axis=1)\n",
    "\n",
    "# Rename column that has epoch_num in it to epoch_num\n",
    "epoch_num_name = [col for col in wide_fooof_func_microvolts.columns if 'epoch_num' in col]\n",
    "wide_fooof_func_microvolts = wide_fooof_func_microvolts.rename(columns={epoch_num_name: 'epoch_num'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_fooof_func_microvolts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert index to string\n",
    "wide_df_fooof_microvolts.index = wide_df_fooof_microvolts.index.astype(str)\n",
    "#Convert index to string\n",
    "wide_fooof_func_microvolts.index = wide_fooof_func_microvolts.index.astype(str)\n",
    "\n",
    "#Reset index\n",
    "wide_df_fooof_microvolts.reset_index(inplace=True)\n",
    "#Reset index\n",
    "wide_fooof_func_microvolts.reset_index(inplace=True)\n",
    "\n",
    "#Set index to subject\n",
    "wide_df_fooof_microvolts = wide_df_fooof_microvolts.set_index('subject')\n",
    "#Set index to subject\n",
    "wide_fooof_func_microvolts = wide_fooof_func_microvolts.set_index('subject')\n",
    "\n",
    "# Set index to string\n",
    "wide_df_fooof_microvolts.index = wide_df_fooof_microvolts.index.astype(str)\n",
    "# Set index to string\n",
    "wide_fooof_func_microvolts.index = wide_fooof_func_microvolts.index.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate the two dataframes\n",
    "wide_df = pd.concat([ wide_fooof_func_microvolts, wide_df_fooof_microvolts], axis=1)\n",
    "#Replace offset with off\n",
    "wide_df.columns = wide_df.columns.str.replace('offset', 'off')\n",
    "#Replace exponent with exp\n",
    "wide_df.columns = wide_df.columns.str.replace('exponent', 'exp')\n",
    "\n",
    "wide_df.reset_index(inplace=True)\n",
    "wide_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "now = datetime.datetime.now()\n",
    "now = now.strftime(\"%Y-%m-%d_%H-%M\")\n",
    "pyreadstat.write_sav(wide_df, os.path.join(home_dir, f\"final_fooof_{project_name}_{now}.sav\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
